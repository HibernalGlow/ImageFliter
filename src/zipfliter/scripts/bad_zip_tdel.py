import os
import subprocess
import json  # å°†yamlæ”¹ä¸ºjson
from datetime import datetime
import concurrent.futures
from functools import partial
import shutil
import argparse
from unittest.mock import DEFAULT
import pyperclip
from pathlib import Path
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from textual_logger import TextualLoggerManager
from nodes.record.logger_config import setup_logger
from loguru import logger
import os
import sys
from pathlib import Path
from datetime import datetime

def setup_logger(app_name="app", project_root=None, console_output=True):
    """é…ç½® Loguru æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        app_name: åº”ç”¨åç§°ï¼Œç”¨äºæ—¥å¿—ç›®å½•
        project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
        console_output: æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œé»˜è®¤ä¸ºTrue
        
    Returns:
        tuple: (logger, config_info)
            - logger: é…ç½®å¥½çš„ logger å®ä¾‹
            - config_info: åŒ…å«æ—¥å¿—é…ç½®ä¿¡æ¯çš„å­—å…¸
    """
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    if project_root is None:
        project_root = Path(__file__).parent.resolve()
    
    # æ¸…é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æœ‰æ¡ä»¶åœ°æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨ï¼ˆç®€æ´ç‰ˆæ ¼å¼ï¼‰
    if console_output:
        logger.add(
            sys.stdout,
            level="INFO",
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <blue>{elapsed}</blue> | <level>{level.icon} {level: <8}</level> | <cyan>{name}:{function}:{line}</cyan> - <level>{message}</level>"
        )
    
    # ä½¿ç”¨ datetime æ„å»ºæ—¥å¿—è·¯å¾„
    current_time = datetime.now()
    date_str = current_time.strftime("%Y-%m-%d")
    hour_str = current_time.strftime("%H")
    minute_str = current_time.strftime("%M%S")
    
    # æ„å»ºæ—¥å¿—ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
    log_dir = os.path.join(project_root, "logs", app_name, date_str, hour_str)
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{minute_str}.log")
    
    # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
    logger.add(
        log_file,
        level="DEBUG",
        rotation="10 MB",
        retention="30 days",
        compression="zip",
        encoding="utf-8",
        format="{time:YYYY-MM-DD HH:mm:ss} | {elapsed} | {level.icon} {level: <8} | {name}:{function}:{line} - {message}",
    )
    
    # åˆ›å»ºé…ç½®ä¿¡æ¯å­—å…¸
    config_info = {
        'log_file': log_file,
    }
    
    logger.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œåº”ç”¨åç§°: {app_name}")
    return logger, config_info

logger, config_info = setup_logger(app_name="badzipfliter", console_output=True)

# è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
# å°†å†å²æ–‡ä»¶ä»yamlæ”¹ä¸ºjson
HISTORY_FILE = os.path.join(SCRIPT_DIR, 'archive_check_history.json')
# ä¿®æ”¹ä¸ºæ”¯æŒå¤šè·¯å¾„çš„åˆ—è¡¨
DEFAULT_PATHS = [
    Path(r"D:\3EHV"),
    Path(r"E:\7EHV"),
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šé»˜è®¤è·¯å¾„
    # Path(r"E:\å…¶ä»–è·¯å¾„"),
    # Path(r"F:\å¦ä¸€ä¸ªè·¯å¾„"),
]
# é…ç½®æ—¥å¿—é¢æ¿å¸ƒå±€
TEXTUAL_LAYOUT = {
    "status": {
        "ratio": 2,
        "title": "ğŸ“Š çŠ¶æ€ä¿¡æ¯",
        "style": "lightblue"
    },
    "progress": {
        "ratio": 2,
        "title": "ğŸ”„ å¤„ç†è¿›åº¦",
        "style": "lightcyan"
    },
    "success": {
        "ratio": 3,
        "title": "âœ… æˆåŠŸä¿¡æ¯",
        "style": "lightgreen"
    },
    "warning": {
        "ratio": 2,
        "title": "âš ï¸ è­¦å‘Šä¿¡æ¯",
        "style": "lightyellow"
    },
    "error": {
        "ratio": 2,
        "title": "âŒ é”™è¯¯ä¿¡æ¯",
        "style": "lightred"
    }
}

# åˆå§‹åŒ–æ—¥å¿—
config = {
    'script_name': 'bad_zip_tdel',
    'console_enabled': False
}
logger, config_info = setup_logger(config)

def load_check_history():
    """åŠ è½½æ£€æµ‹å†å²è®°å½•ï¼ˆä»JSONæ–‡ä»¶ï¼‰"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f) or {}
        except json.JSONDecodeError:
            logger.error(f"[#error] å†å²è®°å½•æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†åˆ›å»ºæ–°çš„å†å²è®°å½•")
            return {}
    return {}

def save_check_history(history):
    """ä¿å­˜æ£€æµ‹å†å²è®°å½•ï¼ˆåˆ°JSONæ–‡ä»¶ï¼‰"""
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

def check_archive(file_path):
    """æ£€æµ‹å‹ç¼©åŒ…æ˜¯å¦æŸå"""
    try:
        result = subprocess.run(['7z', 't', file_path], 
                              capture_output=True, 
                              text=True)
        return result.returncode == 0
    except Exception as e:
        logger.error(f"[#error] âŒ æ£€æµ‹æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False

def get_archive_files(directory, archive_extensions):
    """å¿«é€Ÿæ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶"""
    for root, _, files in os.walk(directory):
        for filename in files:
            if any(filename.lower().endswith(ext) for ext in archive_extensions):
                yield os.path.join(root, filename)

def get_paths_from_clipboard():
    """ä»å‰ªè´´æ¿è¯»å–å¤šè¡Œè·¯å¾„"""
    try:
        clipboard_content = pyperclip.paste()
        if not clipboard_content:
            return []
            
        paths = [
            Path(path.strip().strip('"').strip("'"))
            for path in clipboard_content.splitlines() 
            if path.strip()
        ]
        
        valid_paths = [
            path for path in paths 
            if path.exists()
        ]
        
        if valid_paths:
            logger.info(f"[#status] ğŸ“‹ ä»å‰ªè´´æ¿è¯»å–åˆ° {len(valid_paths)} ä¸ªæœ‰æ•ˆè·¯å¾„")
        else:
            logger.warning("[#warning] âš ï¸ å‰ªè´´æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆè·¯å¾„")
            
        return valid_paths
        
    except Exception as e:
        logger.error(f"[#error] âŒ è¯»å–å‰ªè´´æ¿æ—¶å‡ºé”™: {e}")
        return []

def process_directory(directory, skip_checked=False, max_workers=4):
    """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰å‹ç¼©åŒ…æ–‡ä»¶"""
    archive_extensions = ('.zip', '.rar', '.7z', '.cbz')
    check_history = load_check_history()
    
    # åˆ é™¤temp_å¼€å¤´çš„æ–‡ä»¶å¤¹
    for root, dirs, _ in os.walk(directory, topdown=True):
        for dir_name in dirs[:]:  # ä½¿ç”¨åˆ‡ç‰‡åˆ›å»ºå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨
            if dir_name.startswith('temp_'):
                try:
                    dir_path = os.path.join(root, dir_name)
                    logger.info(f"[#status] ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹: {dir_path}")
                    shutil.rmtree(dir_path)
                except Exception as e:
                    logger.error(f"[#error] åˆ é™¤æ–‡ä»¶å¤¹ {dir_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    # æ”¶é›†éœ€è¦å¤„ç†çš„æ–‡ä»¶
    files_to_process = []
    for root, _, files in os.walk(directory):
        for filename in files:
            if filename.lower().endswith(archive_extensions):
                file_path = os.path.join(root, filename)
                if file_path.endswith('.tdel'):
                    continue
                if skip_checked and file_path in check_history and check_history[file_path]['valid']:
                    logger.info(f"[#status] â­ï¸ è·³è¿‡å·²æ£€æŸ¥ä¸”å®Œå¥½çš„æ–‡ä»¶: {file_path}")
                    continue
                files_to_process.append(file_path)

    if not files_to_process:
        logger.info("[#status] âœ¨ æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶")
        return

    # æ›´æ–°è¿›åº¦ä¿¡æ¯
    total_files = len(files_to_process)
    logger.info(f"[@progress] æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ (0/{total_files}) 0%")

    # å®šä¹‰å•ä¸ªæ–‡ä»¶å¤„ç†å‡½æ•°
    def process_single_file(file_path, file_index):
        logger.info(f"[#status] ğŸ” æ­£åœ¨æ£€æµ‹: {file_path}")
        is_valid = check_archive(file_path)
        result = {
            'path': file_path,
            'valid': is_valid,
            'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        # æ›´æ–°è¿›åº¦
        progress_percentage = int((file_index + 1) / total_files * 100)
        logger.info(f"[@progress] æ£€æµ‹å‹ç¼©åŒ…å®Œæ•´æ€§ ({file_index + 1}/{total_files}) {progress_percentage}%")
        return result

    # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†æ–‡ä»¶
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # ä½¿ç”¨enumerateè·å–ç´¢å¼•ï¼Œæ–¹ä¾¿æ›´æ–°è¿›åº¦
        futures = [executor.submit(process_single_file, file_path, i) for i, file_path in enumerate(files_to_process)]
        
        # å¤„ç†ç»“æœ
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            file_path = result['path']
            is_valid = result['valid']
            
            check_history[file_path] = {
                'time': result['time'],
                'valid': is_valid
            }
            
            if not is_valid:
                new_path = file_path + '.tdel'
                # å¦‚æœ.tdelæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤å®ƒ
                if os.path.exists(new_path):
                    try:
                        os.remove(new_path)
                        logger.info(f"[#status] ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶: {new_path}")
                    except Exception as e:
                        logger.error(f"[#error] åˆ é™¤æ–‡ä»¶ {new_path} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        continue
                
                try:
                    os.rename(file_path, new_path)
                    logger.warning(f"[#warning] âš ï¸ æ–‡ä»¶æŸå,å·²é‡å‘½åä¸º: {new_path}")
                except Exception as e:
                    logger.error(f"[#error] é‡å‘½åæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            else:
                logger.info(f"[#success] âœ… æ–‡ä»¶å®Œå¥½: {file_path}")
            
            # å®šæœŸä¿å­˜æ£€æŸ¥å†å²
            save_check_history(check_history)

    # å¤„ç†ç»“æœçš„å¾ªç¯ç»“æŸåï¼Œæ·»åŠ åˆ é™¤ç©ºæ–‡ä»¶å¤¹çš„åŠŸèƒ½
    removed_count = 0
    logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ (0/100) 0%")
    
    # è·å–ç›®å½•æ€»æ•°ä»¥è®¡ç®—è¿›åº¦
    dir_count = sum(len(dirs) for _, dirs, _ in os.walk(directory))
    processed_dirs = 0
    
    for root, dirs, _ in os.walk(directory, topdown=False):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            try:
                if not os.listdir(dir_path):  # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©º
                    os.rmdir(dir_path)
                    removed_count += 1
                    logger.info(f"[#status] ğŸ—‘ï¸ å·²åˆ é™¤ç©ºæ–‡ä»¶å¤¹: {dir_path}")
            except Exception as e:
                logger.error(f"[#error] åˆ é™¤ç©ºæ–‡ä»¶å¤¹å¤±è´¥ {dir_path}: {str(e)}")
            
            # æ›´æ–°è¿›åº¦
            processed_dirs += 1
            progress = int(processed_dirs / dir_count * 100) if dir_count > 0 else 100
            logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ ({processed_dirs}/{dir_count}) {progress}%")
    
    logger.info(f"[@progress] æ¸…ç†ç©ºæ–‡ä»¶å¤¹ ({dir_count}/{dir_count}) 100%")
    if removed_count > 0:
        logger.info(f"[#success] âœ¨ å…±åˆ é™¤äº† {removed_count} ä¸ªç©ºæ–‡ä»¶å¤¹")

def main():
    parser = argparse.ArgumentParser(description='å‹ç¼©åŒ…å®Œæ•´æ€§æ£€æŸ¥å·¥å…·')
    parser.add_argument('paths', nargs='*', help='è¦å¤„ç†çš„è·¯å¾„åˆ—è¡¨')
    parser.add_argument('-c', '--clipboard', action='store_true', help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    parser.add_argument('--no_tui', action='store_true', help='ä¸ä½¿ç”¨TUIç•Œé¢ï¼Œåªä½¿ç”¨æ§åˆ¶å°è¾“å‡º')
    parser.add_argument('--force_check', action='store_true', help='å¼ºåˆ¶æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶ï¼Œå¿½ç•¥å·²å¤„ç†è®°å½•')
    args = parser.parse_args()

    # æ ¹æ®æ˜¯å¦ä½¿ç”¨TUIé…ç½®æ—¥å¿—
    global logger, config_info
    if args.no_tui:
        # é‡æ–°åˆå§‹åŒ–æ—¥å¿—ï¼Œå¯ç”¨æ§åˆ¶å°è¾“å‡º
        config = {
            'script_name': 'bad_zip_tdel',
            'console_enabled': True
        }
        logger, config_info = setup_logger(config)
        logger.info("å·²ç¦ç”¨TUIç•Œé¢ï¼Œä½¿ç”¨æ§åˆ¶å°è¾“å‡º")
    else:
        # åˆå§‹åŒ–TextualLogger
        TextualLoggerManager.set_layout(TEXTUAL_LAYOUT, config_info['log_file'], newtab=True)
    
    # è·å–è¦å¤„ç†çš„è·¯å¾„
    directories = []
    
    if args.clipboard:
        directories.extend(get_paths_from_clipboard())
    elif args.paths:
        for path_str in args.paths:
            path = Path(path_str.strip('"').strip("'"))
            if path.exists():
                directories.append(path)
            else:
                logger.warning(f"[#warning] âš ï¸ è­¦å‘Šï¼šè·¯å¾„ä¸å­˜åœ¨ - {path_str}")
    else:
        # ä½¿ç”¨é»˜è®¤è·¯å¾„åˆ—è¡¨
        valid_default_paths = []
        for default_path in DEFAULT_PATHS:
            if default_path.exists():
                valid_default_paths.append(default_path)
                logger.info(f"[#status] ğŸ“‚ ä½¿ç”¨é»˜è®¤è·¯å¾„: {default_path}")
            else:
                logger.warning(f"[#warning] âš ï¸ é»˜è®¤è·¯å¾„ä¸å­˜åœ¨: {default_path}")
        
        if valid_default_paths:
            directories.extend(valid_default_paths)
        else:
            logger.error("[#error] âŒ æ‰€æœ‰é»˜è®¤è·¯å¾„éƒ½ä¸å­˜åœ¨")
            return

    if not directories:
        logger.error("[#error] âŒ æœªæä¾›ä»»ä½•æœ‰æ•ˆçš„è·¯å¾„")
        return

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°å†³å®šæ˜¯å¦è·³è¿‡å·²æ£€æŸ¥çš„æ–‡ä»¶
    skip_checked = not args.force_check
    if args.force_check:
        logger.info("[#status] ğŸ”„ å¼ºåˆ¶æ£€æŸ¥æ¨¡å¼ï¼šå°†æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¹‹å‰å·²æ£€æŸ¥è¿‡çš„")
    else:
        logger.info("[#status] â„¹ï¸ æ ‡å‡†æ£€æŸ¥æ¨¡å¼ï¼šå°†è·³è¿‡ä¹‹å‰å·²æ£€æŸ¥ä¸”å®Œå¥½çš„æ–‡ä»¶")
        
    # å¯ä»¥æ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´çº¿ç¨‹æ•°
    max_workers = os.cpu_count() or 4
    
    # å¤„ç†æ¯ä¸ªç›®å½•
    total_dirs = len(directories)
    for idx, directory in enumerate(directories):
        dir_progress = int((idx / total_dirs) * 100) if total_dirs > 0 else 100
        logger.info(f"[@progress] å¤„ç†ç›®å½• ({idx+1}/{total_dirs}) {dir_progress}%")
        logger.info(f"[#status] ğŸ“‚ å¼€å§‹å¤„ç†ç›®å½•: {directory}")
        process_directory(directory, skip_checked, max_workers=max_workers)
        logger.info(f"[#success] âœ… ç›®å½•å¤„ç†å®Œæˆ: {directory}")
    
    # æœ€ç»ˆå®Œæˆ
    logger.info(f"[@progress] å¤„ç†ç›®å½• ({total_dirs}/{total_dirs}) 100%")
    
if __name__ == "__main__":
    main()