"""
Multiæ–‡ä»¶åˆ†æå™¨æ¨¡å—
æä¾›å¯¹å‹ç¼©åŒ…æ–‡ä»¶çš„å®½åº¦ã€é¡µæ•°å’Œæ¸…æ™°åº¦åˆ†æåŠŸèƒ½
æ”¯æŒå‘½ä»¤è¡Œå•ç‹¬è¿è¡Œ
"""

import os
import logging
from typing import List, Dict, Tuple, Union, Optional
from pathlib import Path
import zipfile
from PIL import Image, ImageFile
import pillow_avif
import pillow_jxl
import warnings
import cv2
import numpy as np
from io import BytesIO
import random
from concurrent.futures import ThreadPoolExecutor
from nodes.pics.hash.calculate_hash_custom import ImageClarityEvaluator
from nodes.utils.number_shortener import shorten_number_cn
import re
from nodes.pics.filter.group_analyzer import GroupAnalyzer
import argparse
import json
import sys
from nodes.tui.mode_manager import create_mode_manager
import pyperclip

# æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Š
warnings.filterwarnings('ignore')
# å…è®¸æˆªæ–­çš„å›¾åƒæ–‡ä»¶
ImageFile.LOAD_TRUNCATED_IMAGES = True
# è®¾ç½®OpenCVçš„é”™è¯¯å¤„ç†
 # é™åˆ¶OpenCVçº¿ç¨‹æ•°
 # åªæ˜¾ç¤ºé”™è¯¯æ—¥å¿—

logger = logging.getLogger(__name__)

class MultiAnalyzer:
    """Multiæ–‡ä»¶åˆ†æå™¨ï¼Œç”¨äºåˆ†æå‹ç¼©åŒ…ä¸­å›¾ç‰‡çš„å®½åº¦ã€é¡µæ•°å’Œæ¸…æ™°åº¦"""
    
    def __init__(self, sample_count: int = 3):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            sample_count: æ¯ä¸ªå‹ç¼©åŒ…æŠ½å–çš„å›¾ç‰‡æ ·æœ¬æ•°é‡
        """
        self.sample_count = sample_count
        self.supported_extensions = {
            '.jpg', '.jpeg', '.png', '.webp', '.avif', 
            '.jxl', '.gif', '.bmp', '.tiff', '.tif', 
            '.heic', '.heif'
        }
    
    def get_archive_info(self, archive_path: str) -> List[Tuple[str, int]]:
        """è·å–å‹ç¼©åŒ…ä¸­çš„æ–‡ä»¶ä¿¡æ¯"""
        try:
            image_files = []
            with zipfile.ZipFile(archive_path, 'r') as zf:
                for info in zf.infolist():
                    ext = os.path.splitext(info.filename.lower())[1]
                    if ext in self.supported_extensions:
                        image_files.append((info.filename, info.file_size))
            return image_files
        except Exception as e:
            logger.error(f"è·å–å‹ç¼©åŒ…ä¿¡æ¯å¤±è´¥ {archive_path}: {str(e)}")
            return []

    def get_image_count(self, archive_path: str) -> int:
        """è®¡ç®—å‹ç¼©åŒ…ä¸­çš„å›¾ç‰‡æ€»æ•°"""
        image_files = self.get_archive_info(archive_path)
        return len(image_files)

    def _safe_open_image(self, img_data: bytes) -> Optional[Image.Image]:
        """å®‰å…¨åœ°æ‰“å¼€å›¾ç‰‡ï¼Œå¤„ç†å¯èƒ½çš„è§£ç é”™è¯¯
        
        Args:
            img_data: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
            
        Returns:
            Optional[Image.Image]: æˆåŠŸåˆ™è¿”å›PILå›¾åƒå¯¹è±¡ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        try:
            # é¦–å…ˆå°è¯•ç”¨PILç›´æ¥æ‰“å¼€
            img = Image.open(BytesIO(img_data))
            img.verify()  # éªŒè¯å›¾åƒå®Œæ•´æ€§
            return Image.open(BytesIO(img_data))  # é‡æ–°æ‰“å¼€ä»¥ä¾¿åç»­ä½¿ç”¨
        except Exception as e1:
            try:
                # å¦‚æœPILéªŒè¯å¤±è´¥ï¼Œå°è¯•ç”¨OpenCVæ‰“å¼€
                nparr = np.frombuffer(img_data, np.uint8)
                img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                if img is None:
                    raise ValueError("OpenCVæ— æ³•è§£ç å›¾åƒ")
                # è½¬æ¢ä¸ºRGB
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                return Image.fromarray(img_rgb)
            except Exception as e2:
                try:
                    # æœ€åå°è¯•ç›´æ¥ç”¨PILæ‰“å¼€è€Œä¸éªŒè¯
                    return Image.open(BytesIO(img_data))
                except Exception as e3:
                    logger.debug(f"å›¾åƒè§£ç å¤±è´¥: PIL1={str(e1)}, CV2={str(e2)}, PIL2={str(e3)}")
                    return None

    def calculate_representative_width(self, archive_path: str) -> int:
        """è®¡ç®—å‹ç¼©åŒ…ä¸­å›¾ç‰‡çš„ä»£è¡¨å®½åº¦ï¼ˆä½¿ç”¨æŠ½æ ·å’Œä¸­ä½æ•°ï¼‰"""
        try:
            # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
            archive_path = os.path.abspath(archive_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(archive_path):
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {archive_path}")
                return 0
                
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            ext = os.path.splitext(archive_path)[1].lower()
            if ext not in {'.zip', '.cbz'}:  # åªå¤„ç†zipæ ¼å¼
                return 0

            # è·å–å‹ç¼©åŒ…ä¸­çš„æ–‡ä»¶ä¿¡æ¯
            image_files = []
            try:
                with zipfile.ZipFile(archive_path, 'r') as zf:
                    for info in zf.infolist():
                        if os.path.splitext(info.filename.lower())[1] in self.supported_extensions:
                            image_files.append((info.filename, info.file_size))
            except zipfile.BadZipFile:
                logger.error(f"æ— æ•ˆçš„ZIPæ–‡ä»¶: {archive_path}")
                return 0

            if not image_files:
                return 0

            # æŒ‰æ–‡ä»¶å¤§å°æ’åº
            image_files.sort(key=lambda x: x[1], reverse=True)
            
            # é€‰æ‹©æ ·æœ¬
            samples = []
            if image_files:
                samples.append(image_files[0][0])  # æœ€å¤§çš„æ–‡ä»¶
                if len(image_files) > 2:
                    samples.append(image_files[len(image_files)//2][0])  # ä¸­é—´çš„æ–‡ä»¶
                
                # ä»å‰30%é€‰æ‹©å‰©ä½™æ ·æœ¬
                top_30_percent = image_files[:max(3, len(image_files) // 3)]
                while len(samples) < self.sample_count and top_30_percent:
                    sample = random.choice(top_30_percent)[0]
                    if sample not in samples:
                        samples.append(sample)

            widths = []
            try:
                with zipfile.ZipFile(archive_path, 'r') as zf:
                    for sample in samples:
                        try:
                            with zf.open(sample) as file:
                                img_data = file.read()
                                img = self._safe_open_image(img_data)
                                if img is not None:
                                    widths.append(img.width)
                        except Exception as e:
                            logger.error(f"è¯»å–å›¾ç‰‡å®½åº¦å¤±è´¥ {sample}: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"æ‰“å¼€ZIPæ–‡ä»¶å¤±è´¥: {str(e)}")
                return 0

            if not widths:
                return 0

            # ä½¿ç”¨ä¸­ä½æ•°ä½œä¸ºä»£è¡¨å®½åº¦
            return int(sorted(widths)[len(widths)//2])

        except Exception as e:
            logger.error(f"è®¡ç®—ä»£è¡¨å®½åº¦å¤±è´¥ {archive_path}: {str(e)}")
            return 0

    def calculate_clarity_score(self, archive_path: str) -> float:
        """è®¡ç®—å‹ç¼©åŒ…ä¸­å›¾ç‰‡çš„æ¸…æ™°åº¦è¯„åˆ†"""
        try:
            # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
            archive_path = os.path.abspath(archive_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(archive_path):
                logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {archive_path}")
                return 0.0

            # è·å–å‹ç¼©åŒ…ä¸­çš„æ–‡ä»¶ä¿¡æ¯
            image_files = self.get_archive_info(archive_path)
            if not image_files:
                return 0.0

            # æŒ‰æ–‡ä»¶å¤§å°æ’åºå¹¶é€‰æ‹©æ ·æœ¬
            image_files.sort(key=lambda x: x[1], reverse=True)
            samples = []
            if image_files:
                samples.append(image_files[0][0])  # æœ€å¤§çš„æ–‡ä»¶
                if len(image_files) > 2:
                    samples.append(image_files[len(image_files)//2][0])  # ä¸­é—´çš„æ–‡ä»¶
                
                # ä»å‰30%é€‰æ‹©å‰©ä½™æ ·æœ¬
                top_30_percent = image_files[:max(3, len(image_files) // 3)]
                while len(samples) < self.sample_count and top_30_percent:
                    sample = random.choice(top_30_percent)[0]
                    if sample not in samples:
                        samples.append(sample)

            # è®¡ç®—æ ·æœ¬çš„æ¸…æ™°åº¦è¯„åˆ†
            scores = []
            with zipfile.ZipFile(archive_path, 'r') as zf:
                for sample in samples:
                    try:
                        with zf.open(sample) as f:
                            img_data = f.read()
                            # ç›´æ¥ä¼ é€’äºŒè¿›åˆ¶æ•°æ®ç»™æ¸…æ™°åº¦è®¡ç®—å‡½æ•°
                            try:
                                score = ImageClarityEvaluator.calculate_definition(img_data)
                                if score and score > 0:  # ç¡®ä¿å¾—åˆ°æœ‰æ•ˆçš„åˆ†æ•°
                                    scores.append(score)
                            except Exception as e:
                                logger.debug(f"æ¸…æ™°åº¦è®¡ç®—å¤±è´¥ {sample}: {str(e)}")
                    except Exception as e:
                        logger.debug(f"å¤„ç†å›¾åƒå¤±è´¥ {sample}: {str(e)}")
                        continue

            # è¿”å›å¹³å‡æ¸…æ™°åº¦è¯„åˆ†
            return float(sum(scores) / len(scores)) if scores else 0.0

        except Exception as e:
            logger.error(f"è®¡ç®—æ¸…æ™°åº¦è¯„åˆ†å¤±è´¥ {archive_path}: {str(e)}")
            return 0.0

    def analyze_archive(self, archive_path: str) -> Dict[str, Union[int, float]]:
        """åˆ†æå‹ç¼©åŒ…ï¼Œè¿”å›å®½åº¦ã€é¡µæ•°å’Œæ¸…æ™°åº¦ä¿¡æ¯"""
        result = {
            'width': 0,
            'page_count': 0,
            'clarity_score': 0.0
        }
        
        try:
            # åˆ†åˆ«è®¡ç®—å„é¡¹æŒ‡æ ‡ï¼Œå¤±è´¥ä¸€é¡¹ä¸å½±å“å…¶ä»–é¡¹
            try:
                result['page_count'] = self.get_image_count(archive_path)
                if result['page_count'] == 0:
                    logger.debug(f"æœªæ‰¾åˆ°å›¾ç‰‡: {archive_path}")
                    return result
            except Exception as e:
                logger.error(f"è®¡ç®—é¡µæ•°å¤±è´¥ {archive_path}: {str(e)}")
                
            try:
                result['width'] = self.calculate_representative_width(archive_path)
                if result['width'] == 0:
                    logger.debug(f"æ— æ³•è®¡ç®—å®½åº¦: {archive_path}")
            except Exception as e:
                logger.error(f"è®¡ç®—å®½åº¦å¤±è´¥ {archive_path}: {str(e)}")
                
            try:
                result['clarity_score'] = self.calculate_clarity_score(archive_path)
                if result['clarity_score'] == 0:
                    logger.debug(f"æ— æ³•è®¡ç®—æ¸…æ™°åº¦: {archive_path}")
            except Exception as e:
                logger.error(f"è®¡ç®—æ¸…æ™°åº¦å¤±è´¥ {archive_path}: {str(e)}")
            
            # éªŒè¯ç»“æœæœ‰æ•ˆæ€§
            if result['width'] == 0 and result['page_count'] == 0 and result['clarity_score'] == 0:
                logger.error(f"æ‰€æœ‰æŒ‡æ ‡è®¡ç®—å¤±è´¥ {archive_path}")
                return result
            
            return result
            
        except Exception as e:
            logger.error(f"åˆ†æå‹ç¼©åŒ…å¤±è´¥ {archive_path}: {str(e)}")
            return result

    def format_analysis_result(self, result: Dict[str, Union[int, float]]) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœä¸ºå­—ç¬¦ä¸²"""
        width = result['width']
        count = result['page_count']
        clarity = result['clarity_score']
        
        parts = []
        if width > 0:
            width_str = shorten_number_cn(width, use_w=True)
            parts.append(f"{width_str}@WD")
        if count > 0:
            count_str = shorten_number_cn(count, use_w=True)
            parts.append(f"{count_str}@PX")
        if clarity > 0:
            clarity_int = int(clarity)
            clarity_str = shorten_number_cn(clarity_int, use_w=True)
            parts.append(f"{clarity_str}@DE")
            
        return "{" + ",".join(parts) + "}" if parts else ""

    def process_file_with_count(self, file_path: str, base_dir: str = "") -> Tuple[str, str, Dict[str, Union[int, float]]]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œè¿”å›åŸå§‹è·¯å¾„ã€æ–°è·¯å¾„å’Œåˆ†æç»“æœ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            base_dir: åŸºç¡€ç›®å½•ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Tuple[str, str, Dict]: åŸå§‹è·¯å¾„ã€æ–°è·¯å¾„å’Œåˆ†æç»“æœçš„å…ƒç»„
        """
        # è·å–å®Œæ•´è·¯å¾„
        full_path = os.path.join(base_dir, file_path) if base_dir else file_path
        dir_name = os.path.dirname(full_path)
        file_name = os.path.basename(full_path)
        name, ext = os.path.splitext(file_name)
        
        # ç§»é™¤å·²æœ‰çš„æ ‡è®°
        name = re.sub(r'\{[^}]*@(?:PX|WD|DE)[^}]*\}', '', name)
        
        # åˆ†ææ–‡ä»¶
        result = self.analyze_archive(full_path)
        
        # æ„å»ºæ–°æ–‡ä»¶å
        formatted = self.format_analysis_result(result)
        if formatted:
            name = f"{name}{formatted}"
            
        # æ„å»ºæ–°çš„å®Œæ•´è·¯å¾„
        new_name = f"{name}{ext}"
        new_path = os.path.join(dir_name, new_name) if dir_name else new_name
        
        return full_path, new_path, result

    def process_directory_with_rename(self, input_path: str, do_rename: bool = False, skip_special_dirs: bool = True) -> List[Dict[str, Union[str, Dict[str, Union[int, float]]]]]:
        """å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼Œå¯é€‰æ‹©æ˜¯å¦é‡å‘½å
        
        Args:
            input_path: è¾“å…¥è·¯å¾„
            do_rename: æ˜¯å¦æ‰§è¡Œé‡å‘½åæ“ä½œ
            skip_special_dirs: æ˜¯å¦è·³è¿‡trashå’Œmultiç›®å½•
        """
        results = []
        pending_renames = []  # å­˜å‚¨å¾…é‡å‘½åçš„æ–‡ä»¶ä¿¡æ¯
        group_analyzer = GroupAnalyzer()  # åˆ›å»ºç»„åˆ†æå™¨å®ä¾‹
        
        # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„
        input_path = os.path.abspath(input_path)
        
        # ç”¨äºå­˜å‚¨æ–‡ä»¶ç»„
        file_groups = {}
        
        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰æ–‡ä»¶å¹¶è¿›è¡Œåˆå§‹åˆ†æ
        if os.path.isfile(input_path):
            if input_path.lower().endswith(('.zip', '.cbz')):
                orig_path = input_path  # ä½¿ç”¨ç»å¯¹è·¯å¾„
                new_path, analysis = self.process_file_with_count(orig_path)
                result = {
                    'file': os.path.basename(input_path),
                    'orig_path': orig_path,
                    'analysis': analysis,
                    'formatted': self.format_analysis_result(analysis)
                }
                results.append(result)
                
        elif os.path.isdir(input_path):
            for root, _, files in os.walk(input_path):
                if skip_special_dirs and ('trash' in root or 'multi' in root):
                    logger.info(f"â­ï¸ è·³è¿‡ç›®å½•: {root}")
                    continue
                for file in files:
                    if file.lower().endswith(('.zip', '.cbz')):
                        file_path = os.path.join(root, file)
                        try:
                            orig_path, new_path, analysis = self.process_file_with_count(file_path)
                            result = {
                                'file': os.path.relpath(file_path, input_path),
                                'orig_path': orig_path,
                                'analysis': analysis,
                                'formatted': self.format_analysis_result(analysis)
                            }
                            results.append(result)
                            
                            # å°†æ–‡ä»¶æ·»åŠ åˆ°å¯¹åº”çš„ç»„
                            clean_name = group_analyzer.clean_filename(file)
                            if clean_name not in file_groups:
                                file_groups[clean_name] = []
                            file_groups[clean_name].append(result)
                            
                        except Exception as e:
                            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        # ç¬¬äºŒæ­¥ï¼šå¤„ç†æ¯ä¸ªæ–‡ä»¶ç»„ï¼Œæ‰¾å‡ºæœ€ä¼˜æŒ‡æ ‡
        for group_name, group_results in file_groups.items():
            if len(group_results) > 1:  # åªå¤„ç†æœ‰å¤šä¸ªæ–‡ä»¶çš„ç»„
                logger.info(f"ğŸ“¦ å¤„ç†æ–‡ä»¶ç»„: {group_name}")
                
                # æ‰¾å‡ºæœ€ä¼˜æŒ‡æ ‡
                best_metrics = {
                    'width': 0,  # æœ€å¤§å®½åº¦
                    'page_count': float('inf'),  # æœ€å°é¡µæ•°
                    'clarity_score': 0.0  # æœ€é«˜æ¸…æ™°åº¦
                }
                
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æŒ‡æ ‡éƒ½ç›¸åŒ
                metrics_same = {
                    'width': True,
                    'page_count': True,
                    'clarity_score': True
                }
                
                # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡å€¼
                all_metrics = {
                    'width': set(),
                    'page_count': set(),
                    'clarity_score': set()
                }
                
                # ç¬¬ä¸€è½®ï¼šæ”¶é›†æ‰€æœ‰å€¼å¹¶æ‰¾å‡ºæœ€ä¼˜å€¼
                for result in group_results:
                    analysis = result['analysis']
                    # æ”¶é›†æ‰€æœ‰å€¼
                    if analysis['width'] > 0:
                        all_metrics['width'].add(analysis['width'])
                    if analysis['page_count'] > 0:
                        all_metrics['page_count'].add(analysis['page_count'])
                    if analysis['clarity_score'] > 0:
                        all_metrics['clarity_score'].add(analysis['clarity_score'])
                    
                    # æ›´æ–°æœ€ä¼˜å€¼
                    best_metrics['width'] = max(best_metrics['width'], analysis['width'])
                    best_metrics['page_count'] = min(best_metrics['page_count'], analysis['page_count'])
                    best_metrics['clarity_score'] = max(best_metrics['clarity_score'], analysis['clarity_score'])
                
                # æ£€æŸ¥æ¯ä¸ªæŒ‡æ ‡æ˜¯å¦éƒ½ç›¸åŒ
                metrics_same['width'] = len(all_metrics['width']) <= 1
                metrics_same['page_count'] = len(all_metrics['page_count']) <= 1
                metrics_same['clarity_score'] = len(all_metrics['clarity_score']) <= 1
                
                # è®°å½•æœ€ä¼˜æŒ‡æ ‡
                best_metrics_info = {
                    'width': best_metrics['width'],
                    'page_count': best_metrics['page_count'] if best_metrics['page_count'] != float('inf') else 0,
                    'clarity_score': best_metrics['clarity_score']
                }
                
                logger.info(f"ğŸ† ç»„æœ€ä¼˜æŒ‡æ ‡: å®½åº¦={best_metrics_info['width']}, é¡µæ•°={best_metrics_info['page_count']}, æ¸…æ™°åº¦={best_metrics_info['clarity_score']}")
                
                # ä¸ºæ¯ä¸ªæ–‡ä»¶æ›´æ–°æ ¼å¼åŒ–æŒ‡æ ‡
                for result in group_results:
                    analysis = result['analysis']
                    parts = []
                    
                    # æ·»åŠ å®½åº¦ï¼ˆå¦‚æœä¸æ˜¯ç»Ÿä¸€å€¼ä¸”æ˜¯æœ€ä¼˜å€¼åˆ™æ·»åŠ è¡¨æƒ…ï¼‰
                    if analysis['width'] > 0:
                        width_str = f"{shorten_number_cn(analysis['width'], use_w=True)}@WD"
                        if not metrics_same['width'] and analysis['width'] == best_metrics['width']:
                            width_str = f"ğŸ“{width_str}"
                        parts.append(width_str)
                    
                    # æ·»åŠ é¡µæ•°ï¼ˆå¦‚æœä¸æ˜¯ç»Ÿä¸€å€¼ä¸”æ˜¯æœ€ä¼˜å€¼åˆ™æ·»åŠ è¡¨æƒ…ï¼‰
                    if analysis['page_count'] > 0:
                        page_str = f"{shorten_number_cn(analysis['page_count'], use_w=True)}@PX"
                        if not metrics_same['page_count'] and analysis['page_count'] == best_metrics['page_count']:
                            page_str = f"ğŸ“„{page_str}"
                        parts.append(page_str)
                    
                    # æ·»åŠ æ¸…æ™°åº¦ï¼ˆå¦‚æœä¸æ˜¯ç»Ÿä¸€å€¼ä¸”æ˜¯æœ€ä¼˜å€¼åˆ™æ·»åŠ è¡¨æƒ…ï¼‰
                    if analysis['clarity_score'] > 0:
                        clarity_str = f"{shorten_number_cn(int(analysis['clarity_score']), use_w=True)}@DE"
                        if not metrics_same['clarity_score'] and analysis['clarity_score'] == best_metrics['clarity_score']:
                            clarity_str = f"ğŸ”{clarity_str}"
                        parts.append(clarity_str)
                    
                    result['formatted'] = "{" + ",".join(parts) + "}" if parts else ""
        
        # ç¬¬ä¸‰æ­¥ï¼šå‡†å¤‡é‡å‘½åæ“ä½œ
        for result in results:
            orig_path = result['orig_path']
            dir_name = os.path.dirname(orig_path)
            file_name = os.path.basename(orig_path)
            name, ext = os.path.splitext(file_name)
            
            # ç§»é™¤å·²æœ‰çš„æ ‡è®°
            name = re.sub(r'\{[^}]*@(?:PX|WD|DE)[^}]*\}', '', name)
            
            # æ·»åŠ æ–°çš„æ ¼å¼åŒ–æŒ‡æ ‡
            if result['formatted']:
                name = f"{name}{result['formatted']}"
            
            # æ„å»ºæ–°çš„å®Œæ•´è·¯å¾„
            new_name = f"{name}{ext}"
            new_path = os.path.join(dir_name, new_name) if dir_name else new_name
            result['new_name'] = os.path.basename(new_path)
            
            if do_rename and orig_path != new_path:
                pending_renames.append((orig_path, new_path, result))
        
        # ç¬¬å››æ­¥ï¼šæ‰§è¡Œé‡å‘½åæ“ä½œ
        if do_rename and pending_renames:
            print("\nå¼€å§‹é‡å‘½åæ–‡ä»¶...")
            for orig_path, new_path, result in pending_renames:
                try:
                    if os.path.exists(orig_path):
                        os.rename(orig_path, new_path)
                        result['renamed'] = True
                        print(f"é‡å‘½åæˆåŠŸ: {os.path.basename(orig_path)} -> {os.path.basename(new_path)}")
                    else:
                        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {orig_path}")
                        result['renamed'] = False
                except Exception as e:
                    logger.error(f"é‡å‘½åå¤±è´¥ {orig_path}: {str(e)}")
                    result['renamed'] = False
                    print(f"é‡å‘½åå¤±è´¥: {os.path.basename(orig_path)} ({str(e)})")
                    
        return results

def setup_cli_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description='Multiæ–‡ä»¶åˆ†æå™¨')
    group = parser.add_mutually_exclusive_group()
    group.add_argument('-c', '--clipboard', action='store_true', help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    group.add_argument('input_path', nargs='?', help='è¾“å…¥æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('-s', '--sample-count', type=int, default=3, help='æ¯ä¸ªå‹ç¼©åŒ…æŠ½å–çš„å›¾ç‰‡æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤3ï¼‰')
    parser.add_argument('-r', '--rename', action='store_true', help='æ‰§è¡Œé‡å‘½åæ“ä½œ')
    parser.add_argument('--no-skip-special', action='store_true', help='ä¸è·³è¿‡trashå’Œmultiç›®å½•')
    parser.add_argument('-o', '--output', help='ä¿å­˜ç»“æœçš„æ–‡ä»¶è·¯å¾„')
    return parser

def get_paths_from_clipboard():
    """ä»å‰ªè´´æ¿è¯»å–å¤šè¡Œè·¯å¾„"""
    try:
        clipboard_content = pyperclip.paste()
        if not clipboard_content:
            return []
            
        # åˆ†å‰²å¤šè¡Œå†…å®¹å¹¶æ¸…ç†
        paths = [
            path.strip().strip('"').strip("'")
            for path in clipboard_content.splitlines() 
            if path.strip()
        ]
        
        # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
        valid_paths = [
            path for path in paths 
            if os.path.exists(path)
        ]
        
        if valid_paths:
            logger.info("[#file_ops] ğŸ“‹ ä»å‰ªè´´æ¿è¯»å–åˆ° %d ä¸ªæœ‰æ•ˆè·¯å¾„", len(valid_paths))
        else:
            logger.info("[#error_log] âš ï¸ å‰ªè´´æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆè·¯å¾„")
            
        return valid_paths
        
    except Exception as e:
        logger.info("[#error_log] âŒ è¯»å–å‰ªè´´æ¿æ—¶å‡ºé”™: %s", e)
        return []

def run_application(args):
    """è¿è¡Œåº”ç”¨ç¨‹åº"""
    input_paths = []
    
    # ä»å‰ªè´´æ¿è¯»å–
    if args.clipboard:
        clipboard_paths = get_paths_from_clipboard()
        if not clipboard_paths:
            print("é”™è¯¯ï¼šå‰ªè´´æ¿ä¸­æ²¡æœ‰æœ‰æ•ˆè·¯å¾„")
            return False
        input_paths.extend(clipboard_paths)
    # ä»å‘½ä»¤è¡Œå‚æ•°è¯»å–
    elif args.input_path:
        input_paths.append(args.input_path)
    else:
        print("é”™è¯¯ï¼šæœªæä¾›è¾“å…¥è·¯å¾„ï¼Œä¸”æœªå¯ç”¨å‰ªè´´æ¿è¯»å–")
        return False

    # æ‰§è¡Œåˆ†æ
    print("\nå¼€å§‹åˆ†æ...")
    analyzer = MultiAnalyzer(sample_count=args.sample_count)
    
    all_results = []
    for path in input_paths:
        results = analyzer.process_directory_with_rename(
            path,
            do_rename=args.rename,
            skip_special_dirs=not args.no_skip_special
        )
        all_results.extend(results)

    # ä¿å­˜ç»“æœ
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        print(f"\nç»“æœå·²ä¿å­˜åˆ°: {args.output}")

    # æ˜¾ç¤ºç»“æœ
    print("\nåˆ†æç»“æœ:")
    for result in all_results:
        print(f"åŸæ–‡ä»¶: {result['file']}")
        if args.rename:
            status = "æˆåŠŸ" if result.get('renamed', False) else "å¤±è´¥"
            print(f"æ–°æ–‡ä»¶: {result['new_name']} (é‡å‘½å{status})")
        print(f"åˆ†æç»“æœ: {result['formatted']}")
        print("-" * 50)

    print("\nåˆ†æå®Œæˆï¼")
    return True

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œè¿è¡Œ"""
    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    config_path = os.path.join(os.path.dirname(__file__), 'multi_analyzer_config.json')
    
    # åˆ›å»ºé…ç½®
    config = {
        'tui_config': {
            'title': 'Multiæ–‡ä»¶åˆ†æå™¨é…ç½®',
            'checkbox_options': [
                ('æ‰§è¡Œé‡å‘½åæ“ä½œ', 'rename', '--rename', False),
                ('ä¸è·³è¿‡trashå’Œmultiç›®å½•', 'skip_special', '--no-skip-special', False),
                ('ä»å‰ªè´´æ¿è¯»å–è·¯å¾„', 'clipboard', '--clipboard', False)
            ],
            'input_options': [
                ('é‡‡æ ·æ•°é‡', 'sample_count', '--sample-count', '3', 'æ¯ä¸ªå‹ç¼©åŒ…æŠ½å–çš„å›¾ç‰‡æ ·æœ¬æ•°é‡'),
                ('ç»“æœä¿å­˜è·¯å¾„', 'output', '--output', 'analysis_result.json', 'åˆ†æç»“æœä¿å­˜çš„JSONæ–‡ä»¶è·¯å¾„'),
                ('è¾“å…¥è·¯å¾„', 'input_path', 'input_path', '', 'è¦åˆ†æçš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼ˆä¸ä½¿ç”¨å‰ªè´´æ¿æ—¶éœ€è¦ï¼‰')
            ],
            'preset_configs': {
                'æ ‡å‡†åˆ†æ': {
                    'description': 'æ ‡å‡†åˆ†æé…ç½®',
                    'checkbox_options': ['rename'],
                    'input_values': {
                        'sample_count': '3',
                        'output': 'analysis_result.json',
                        'input_path': ''
                    }
                },
                'å®Œæ•´åˆ†æ': {
                    'description': 'åˆ†ææ‰€æœ‰ç›®å½•ï¼ˆåŒ…æ‹¬trashå’Œmultiï¼‰',
                    'checkbox_options': ['rename', 'skip_special'],
                    'input_values': {
                        'sample_count': '3',
                        'output': 'analysis_result.json',
                        'input_path': ''
                    }
                }
            }
        },
        'debug_config': {
            'base_modes': {
                '1': {
                    'name': 'æ ‡å‡†åˆ†ææ¨¡å¼ï¼ˆä»å‰ªè´´æ¿è¯»å–ï¼‰',
                    'base_args': ['--sample-count', '3', '--clipboard', '--rename'],
                    'default_params': {}
                },
                '2': {
                    'name': 'æ ‡å‡†åˆ†ææ¨¡å¼ï¼ˆæ‰‹åŠ¨è¾“å…¥è·¯å¾„ï¼‰',
                    'base_args': ['--sample-count', '3', '--rename'],
                    'default_params': {}
                },
                '3': {
                    'name': 'å®Œæ•´åˆ†ææ¨¡å¼ï¼ˆä»å‰ªè´´æ¿è¯»å–ï¼‰',
                    'base_args': ['--sample-count', '3', '--no-skip-special', '--clipboard', '--rename'],
                    'default_params': {}
                },
                '4': {
                    'name': 'å®Œæ•´åˆ†ææ¨¡å¼ï¼ˆæ‰‹åŠ¨è¾“å…¥è·¯å¾„ï¼‰',
                    'base_args': ['--sample-count', '3', '--no-skip-special', '--rename'],
                    'default_params': {}
                }
            },
            'param_options': {
                'input_path': {
                    'prompt': 'è¯·è¾“å…¥è¦å¤„ç†çš„è·¯å¾„: ',
                    'required': True
                }
            }
        }
    }

    # åˆ›å»ºæ¨¡å¼ç®¡ç†å™¨
    mode_manager = create_mode_manager(
        config=config,
        cli_parser_setup=setup_cli_parser,
        application_runner=run_application
    )

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©è¿è¡Œæ¨¡å¼
    if len(sys.argv) > 1:
        # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥è¿è¡ŒCLIæ¨¡å¼
        mode_manager.run_cli(sys.argv[1:])
    else:
        # å¦åˆ™æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©èœå•
        print("\n=== è¿è¡Œæ¨¡å¼é€‰æ‹© ===")
        print("1. TUIç•Œé¢æ¨¡å¼")
        print("2. è°ƒè¯•æ¨¡å¼")
        print("3. å‘½ä»¤è¡Œæ¨¡å¼")
        
        try:
            # choice = input("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼ (1-3): ").strip()
            choice = "2"
            if choice == "1":
                mode_manager.run_tui()
            elif choice == "2":
                mode_manager.run_debug()
            elif choice == "3":
                mode_manager.run_cli()
            else:
                print("æ— æ•ˆçš„é€‰æ‹©ï¼Œé€€å‡ºç¨‹åº")
        except KeyboardInterrupt:
            print("\nç”¨æˆ·å–æ¶ˆæ“ä½œ")
        except Exception as e:
            print(f"è¿è¡Œå‡ºé”™: {e}")

if __name__ == '__main__':
    main() 