from pathlib import Path
import sys
import os
import json
import logging
from typing import List, Dict, Set, Tuple
import time
import subprocess
import argparse
import pyperclip
from textual_preset import create_config_app, ConfigOption, CheckboxOption, InputOption, PresetConfig
from common.backup import BackupHandler
from common.archive_process import ArchiveHandler
from nodes.pics.filter.image_filter_old import ImageFilter
from common.input import InputHandler
from common.path import PathHandler, ExtractMode
import platform
import stat
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
import multiprocessing
import zipfile
import shutil
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¸¸é‡
SUPPORTED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.webp', '.gif', '.bmp', '.avif', '.heic', '.heif', '.jxl'}

from loguru import logger
import os
import sys
from pathlib import Path
from datetime import datetime

def setup_logger(app_name="app", project_root=None, console_output=True):
    """é…ç½® Loguru æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        app_name: åº”ç”¨åç§°ï¼Œç”¨äºæ—¥å¿—ç›®å½•
        project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
        console_output: æ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œé»˜è®¤ä¸ºTrue
        
    Returns:
        tuple: (logger, config_info)
            - logger: é…ç½®å¥½çš„ logger å®ä¾‹
            - config_info: åŒ…å«æ—¥å¿—é…ç½®ä¿¡æ¯çš„å­—å…¸
    """
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    if project_root is None:
        project_root = Path(__file__).parent.resolve()
    
    # æ¸…é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()
    
    # æœ‰æ¡ä»¶åœ°æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨ï¼ˆç®€æ´ç‰ˆæ ¼å¼ï¼‰
    if console_output:
        logger.add(
            sys.stdout,
            level="INFO",
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <blue>{elapsed}</blue> | <level>{level.icon} {level: <8}</level> | <cyan>{name}:{function}:{line}</cyan> - <level>{message}</level>"
        )
    
    # ä½¿ç”¨ datetime æ„å»ºæ—¥å¿—è·¯å¾„
    current_time = datetime.now()
    date_str = current_time.strftime("%Y-%m-%d")
    hour_str = current_time.strftime("%H")
    minute_str = current_time.strftime("%M%S")
    
    # æ„å»ºæ—¥å¿—ç›®å½•å’Œæ–‡ä»¶è·¯å¾„
    log_dir = os.path.join(project_root, "logs", app_name, date_str, hour_str)
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{minute_str}.log")
    
    # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
    logger.add(
        log_file,
        level="DEBUG",
        rotation="10 MB",
        retention="30 days",
        compression="zip",
        encoding="utf-8",
        format="{time:YYYY-MM-DD HH:mm:ss} | {elapsed} | {level.icon} {level: <8} | {name}:{function}:{line} - {message}",
    )
    
    # åˆ›å»ºé…ç½®ä¿¡æ¯å­—å…¸
    config_info = {
        'log_file': log_file,
    }
    
    logger.info(f"æ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œåº”ç”¨åç§°: {app_name}")
    return logger, config_info

logger, config_info = setup_logger(app_name="recruit_cover_filter", console_output=False)
BACKUP_ENABLED = True
DEBUG_MODE = False
from textual_logger import TextualLoggerManager
TEXTUAL_LAYOUT = {
    # "global_progress": {
    #     "ratio": 1,
    #     "title": "ğŸŒ æ€»ä½“è¿›åº¦",
    #     "style": "lightyellow"
    # },
    "path_progress": {
        "ratio": 2,
        "title": "ğŸ”„ å½“å‰è¿›åº¦",
        "style": "lightcyan"
    },
    "file_ops": {
        "ratio": 4,
        "title": "ğŸ“‚ æ–‡ä»¶æ“ä½œ",
        "style": "lightpink"
    },
    "sys_log": {
        "ratio": 3,
        "title": "ğŸ”§ ç³»ç»Ÿæ¶ˆæ¯",
        "style": "lightgreen"
    }
}

def initialize_textual_logger(layout: dict, log_file: str) -> None:
    """
    åˆå§‹åŒ–æ—¥å¿—å¸ƒå±€
    
    Args:
        layout: å¸ƒå±€é…ç½®å­—å…¸
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
    """
    try:
        TextualLoggerManager.set_layout(layout, config_info['log_file'])
        logger.info("[#sys_log]âœ… æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}") 

class RecruitCoverFilter:
    """å°é¢å›¾ç‰‡è¿‡æ»¤å™¨"""
    
    def __init__(self, hash_file: str = None, hamming_threshold: int = 16, watermark_keywords: List[str] = None, max_workers: int = None):
        """åˆå§‹åŒ–è¿‡æ»¤å™¨"""
        self.image_filter = ImageFilter(hash_file, hamming_threshold)
        self.watermark_keywords = watermark_keywords
        self.max_workers = max_workers or multiprocessing.cpu_count()
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
        initialize_textual_logger(TEXTUAL_LAYOUT, config_info['log_file'])
        
    def prepare_hash_file(self, recruit_folder: str, workers: int = 16, force_update: bool = False) -> str:
        """
        å‡†å¤‡å“ˆå¸Œæ–‡ä»¶
        
        Args:
            recruit_folder: æ‹›å‹Ÿæ–‡ä»¶å¤¹è·¯å¾„
            workers: å·¥ä½œçº¿ç¨‹æ•°
            force_update: æ˜¯å¦å¼ºåˆ¶æ›´æ–°
            
        Returns:
            str: å“ˆå¸Œæ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            from nodes.pics.filter.hash_process_config import process_artist_folder
            hash_file = process_artist_folder(recruit_folder, workers, force_update)
            if hash_file:
                logger.info(f"[#sys_log]âœ… æˆåŠŸç”Ÿæˆå“ˆå¸Œæ–‡ä»¶: {hash_file}")
                self.image_filter.hash_file = hash_file
                self.image_filter.hash_cache = self.image_filter._load_hash_file()
                return hash_file
            else:
                logger.error("[#sys_log]âŒ ç”Ÿæˆå“ˆå¸Œæ–‡ä»¶å¤±è´¥")
                return None
        except Exception as e:
            logger.error(f"[#sys_log]âŒ å‡†å¤‡å“ˆå¸Œæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def _robust_cleanup(self, temp_dir: str) -> None:
        """æ›´å¥å£®çš„æ–‡ä»¶æ¸…ç†æ–¹æ³•ï¼Œå¤„ç†æ–‡ä»¶è¢«å ç”¨çš„æƒ…å†µ"""
        if not os.path.exists(temp_dir):
            return

        def on_rm_error(func, path, exc_info):
            try:
                os.chmod(path, stat.S_IWRITE)
                os.unlink(path)
                logger.info(f"[#file_ops]æˆåŠŸåˆ é™¤ {path}")
            except Exception as e:
                logger.warning(f"[#file_ops]æ— æ³•åˆ é™¤ {path}: {e}")

        try:
            # å°è¯•æ ‡å‡†åˆ é™¤
            shutil.rmtree(temp_dir, onerror=on_rm_error)
        except Exception as e:
            logger.warning(f"[#file_ops]æ ‡å‡†åˆ é™¤å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶åˆ é™¤: {temp_dir}")
            try:
                # ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤å¼ºåˆ¶åˆ é™¤ï¼ˆWindowsï¼‰
                if platform.system() == 'Windows':
                    subprocess.run(f'rmdir /s /q "{temp_dir}"', shell=True, check=True)
                else:  # Linux/MacOS
                    subprocess.run(f'rm -rf "{temp_dir}"', shell=True, check=True)
            except subprocess.CalledProcessError as e:
                logger.error(f"[#sys_log]å¼ºåˆ¶åˆ é™¤å¤±è´¥: {temp_dir}")
                raise

    def process_archive(self, zip_path: str, extract_mode: str = ExtractMode.ALL, extract_params: dict = None, is_dehash_mode: bool = False) -> Tuple[bool, str]:
        """å¤„ç†å•ä¸ªå‹ç¼©åŒ…
        
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, å¤±è´¥åŸå› )
        """
        logger.info(f"[#file_ops]å¼€å§‹å¤„ç†å‹ç¼©åŒ…: {zip_path}")
        
        # åˆ—å‡ºå‹ç¼©åŒ…å†…å®¹å¹¶é¢„å…ˆè¿‡æ»¤å›¾ç‰‡æ–‡ä»¶
        files = [f for f in ArchiveHandler.list_archive_contents(zip_path)
                if PathHandler.get_file_extension(f).lower() in SUPPORTED_EXTENSIONS]
        
        if not files:
            logger.info("[#file_ops]æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œè·³è¿‡å¤„ç†æ­¤å‹ç¼©åŒ…")
            logger.info(f"[#path_progress]è·³è¿‡å¤„ç†: {os.path.basename(zip_path)}")
            logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 100%")
            return True, "æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œå·²è·³è¿‡"
            
        # è·å–è¦è§£å‹çš„æ–‡ä»¶ç´¢å¼•
        extract_params = extract_params or {}
        
        # å¦‚æœæŒ‡å®šäº†front_næˆ–back_nï¼Œå¼ºåˆ¶ä½¿ç”¨RANGEæ¨¡å¼
        if extract_params.get('front_n', 0) > 0 or extract_params.get('back_n', 0) > 0:
            extract_mode = ExtractMode.RANGE
            logger.info(f"[#file_ops]ä½¿ç”¨å‰åNå¼ æ¨¡å¼: front_n={extract_params.get('front_n', 0)}, back_n={extract_params.get('back_n', 0)}")
        
        # è·å–é€‰ä¸­çš„æ–‡ä»¶ç´¢å¼•
        selected_indices = ExtractMode.get_selected_indices(extract_mode, len(files), extract_params)
        
        # è®°å½•é€‰ä¸­çš„æ–‡ä»¶ä¿¡æ¯
        logger.info(f"[#file_ops]æ€»æ–‡ä»¶æ•°: {len(files)}, é€‰ä¸­æ–‡ä»¶æ•°: {len(selected_indices)}")
        if len(selected_indices) > 0:
            logger.info(f"[#file_ops]é€‰ä¸­çš„æ–‡ä»¶ç´¢å¼•: {sorted(selected_indices)}")
            
        if not selected_indices:
            logger.error("[#file_ops]æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶è¿›è¡Œè§£å‹")
            return False, "æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶è¿›è¡Œè§£å‹"
            
        # ç”Ÿæˆè§£å‹ç›®å½•åç§°
        zip_name = os.path.splitext(os.path.basename(zip_path))[0]
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        extract_dir = os.path.join(os.path.dirname(zip_path), f"temp_{zip_name}_{timestamp}")
            
        # è§£å‹é€‰å®šæ–‡ä»¶
        selected_files = [files[i] for i in selected_indices]
        logger.info(f"[#sys_log]å‡†å¤‡è§£å‹æ–‡ä»¶: {[os.path.basename(f) for f in selected_files]}")
        
        # æ›´æ–°è§£å‹è¿›åº¦
        logger.info(f"[#path_progress]è§£å‹æ–‡ä»¶: {os.path.basename(zip_path)}")
        logger.info(f"[#path_progress]å½“å‰è¿›åº¦: 0%")

        success, extract_dir = ArchiveHandler.extract_files(zip_path, selected_files, extract_dir)
        if not success:
            logger.info(f"[#path_progress]è§£å‹æ–‡ä»¶: {os.path.basename(zip_path)} (å¤±è´¥)")
            return False, "è§£å‹æ–‡ä»¶å¤±è´¥"
        logger.info(f"[#path_progress]è§£å‹æ–‡ä»¶: {os.path.basename(zip_path)}")
        logger.info(f"[#path_progress]å½“å‰è¿›åº¦: 50%")
            
        try:
            # è·å–è§£å‹åçš„å›¾ç‰‡æ–‡ä»¶
            image_files = [
                PathHandler.join_paths(root, file)
                for root, _, files in os.walk(extract_dir)
                for file in files
                if PathHandler.get_file_extension(file).lower() in SUPPORTED_EXTENSIONS
            ]
                        
            # å¤„ç†å›¾ç‰‡
            to_delete, removal_reasons = self.image_filter.process_images(
                image_files,
                enable_duplicate_filter=True,   # å¯ç”¨é‡å¤å›¾ç‰‡è¿‡æ»¤
                duplicate_filter_mode='hash' if self.image_filter.hash_file else 'watermark',  # å¦‚æœæœ‰å“ˆå¸Œæ–‡ä»¶åˆ™ä½¿ç”¨å“ˆå¸Œæ¨¡å¼
                watermark_keywords=None if is_dehash_mode else self.watermark_keywords  # å»æ±‰åŒ–æ¨¡å¼ä¸å¯ç”¨æ°´å°æ£€æµ‹
            )
            
            if not to_delete:
                logger.info("[#sys_log]æ²¡æœ‰éœ€è¦åˆ é™¤çš„å›¾ç‰‡")
                self._robust_cleanup(extract_dir)
                logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(zip_path)}")
                logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 100%")
                return True, "æ²¡æœ‰éœ€è¦åˆ é™¤çš„å›¾ç‰‡"
                
            # å¤‡ä»½è¦åˆ é™¤çš„æ–‡ä»¶
            backup_results = BackupHandler.backup_removed_files(zip_path, to_delete, removal_reasons)
            
            # ä»å‹ç¼©åŒ…ä¸­åˆ é™¤æ–‡ä»¶
            files_to_delete = [os.path.relpath(file_path, extract_dir) for file_path in to_delete]
            logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(zip_path)}")
            logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 75%")
                
            # ä½¿ç”¨7zåˆ é™¤æ–‡ä»¶
            delete_list_file = os.path.join(extract_dir, '@delete.txt')
            with open(delete_list_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(files_to_delete))
            
            # åœ¨æ‰§è¡Œåˆ é™¤æ“ä½œå‰å¤‡ä»½åŸå§‹å‹ç¼©åŒ…
            if BACKUP_ENABLED:
                backup_success, backup_path = BackupHandler.backup_source_file(zip_path)
                if backup_success:
                    logger.info(f"[#sys_log]âœ… æºæ–‡ä»¶å¤‡ä»½æˆåŠŸ: {backup_path}")
                else:
                    logger.warning(f"[#sys_log]âš ï¸ æºæ–‡ä»¶å¤‡ä»½å¤±è´¥: {backup_path}")
                    return False, "æºæ–‡ä»¶å¤‡ä»½å¤±è´¥"
            else:
                logger.info("[#sys_log]â„¹ï¸ å¤‡ä»½åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡å¤‡ä»½")
                backup_success = True

            # ä½¿ç”¨7zåˆ é™¤æ–‡ä»¶
            cmd = ['7z', 'd', zip_path, f'@{delete_list_file}']
            result = subprocess.run(cmd, capture_output=True, text=True)
            os.remove(delete_list_file)
            
            if result.returncode != 0:
                logger.error(f"[#sys_log]ä»å‹ç¼©åŒ…åˆ é™¤æ–‡ä»¶å¤±è´¥: {result.stderr}")
                self._robust_cleanup(extract_dir)
                logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(zip_path)} (å¤±è´¥)")
                return False, f"ä»å‹ç¼©åŒ…åˆ é™¤æ–‡ä»¶å¤±è´¥: {result.stderr}"
                
            logger.info(f"[#file_ops]æˆåŠŸå¤„ç†å‹ç¼©åŒ…: {zip_path}")
            self._robust_cleanup(extract_dir)
            logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(zip_path)}")
            logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 100%")
            return True, ""
            
        except Exception as e:
            logger.error(f"[#sys_log]å¤„ç†å‹ç¼©åŒ…å¤±è´¥ {zip_path}: {e}")
            self._robust_cleanup(extract_dir)
            logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(zip_path)} (é”™è¯¯)")
            return False, f"å¤„ç†è¿‡ç¨‹å‡ºé”™: {str(e)}"

class Application:
    """åº”ç”¨ç¨‹åºç±»"""
    
    def __init__(self, max_workers: int = None):
        """åˆå§‹åŒ–åº”ç”¨ç¨‹åº
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°
        """
        self.max_workers = max_workers or multiprocessing.cpu_count()
        self.archive_queue = Queue()
        
    def _process_single_archive(self, args):
        """å¤„ç†å•ä¸ªå‹ç¼©åŒ…æˆ–ç›®å½•çš„åŒ…è£…å‡½æ•°
        
        Args:
            args: åŒ…å«å¤„ç†å‚æ•°çš„å…ƒç»„ (path, filter_instance, extract_params, is_dehash_mode)
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, å¤±è´¥åŸå› )
        """
        path, filter_instance, extract_params, is_dehash_mode = args
        try:
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not os.path.exists(path):
                raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {path}")
                
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å¯è®¿é—®
            if not os.access(path, os.R_OK):
                raise PermissionError(f"è·¯å¾„æ— æ³•è®¿é—®: {path}")
            
            # å®šä¹‰é»‘åå•å…³é”®è¯
            blacklist_keywords = ["ç”»é›†", "CG", "02cos", "01æ‚", "å›¾é›†"]
            
            # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰zipæ–‡ä»¶
            if os.path.isdir(path):
                success = True
                error_msg = ""
                for root, _, files in os.walk(path):
                    # æ£€æŸ¥å½“å‰ç›®å½•è·¯å¾„æ˜¯å¦åŒ…å«é»‘åå•å…³é”®è¯
                    root_lower = root.lower()
                    if any(kw in root_lower for kw in blacklist_keywords):
                        logger.info(f"[#sys_log]è·³è¿‡é»‘åå•ç›®å½•: {root}")
                        continue
                        
                    for file in files:
                        if file.lower().endswith('.zip'):
                            zip_path = os.path.join(root, file)
                            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«é»‘åå•å…³é”®è¯
                            if any(kw in file.lower() for kw in blacklist_keywords):
                                logger.info(f"[#sys_log]è·³è¿‡é»‘åå•æ–‡ä»¶: {file}")
                                continue
                                
                            try:
                                if not zipfile.is_zipfile(zip_path):
                                    logger.warning(f"[#sys_log]è·³è¿‡æ— æ•ˆçš„ZIPæ–‡ä»¶: {zip_path}")
                                    continue
                                    
                                # å¤„ç†å•ä¸ªzipæ–‡ä»¶
                                file_success, file_error = filter_instance.process_archive(
                                    zip_path,
                                    extract_mode=ExtractMode.RANGE,  # é»˜è®¤ä½¿ç”¨RANGEæ¨¡å¼
                                    extract_params=extract_params,
                                    is_dehash_mode=is_dehash_mode
                                )
                                if not file_success:
                                    logger.warning(f"[#file_ops]å¤„ç†è¿”å›å¤±è´¥: {os.path.basename(zip_path)}, åŸå› : {file_error}")
                                    error_msg = file_error
                                    continue
                                success = success and file_success
                            except Exception as e:
                                error_msg = str(e)
                                logger.error(f"[#file_ops]å¤„ç†ZIPæ–‡ä»¶å¤±è´¥ {zip_path}: {error_msg}")
                                success = False
                return success, error_msg
                
            # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç¡®ä¿æ˜¯zipæ–‡ä»¶
            elif path.lower().endswith('.zip'):
                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«é»‘åå•å…³é”®è¯
                if any(kw in os.path.basename(path).lower() for kw in blacklist_keywords):
                    logger.info(f"[#file_ops]è·³è¿‡é»‘åå•æ–‡ä»¶: {os.path.basename(path)}")
                    return False, "é»‘åå•æ–‡ä»¶"
                    
                # if not zipfile.is_zipfile(path):
                #     raise ValueError(f"ä¸æ˜¯æœ‰æ•ˆçš„ZIPæ–‡ä»¶: {path}")
                    
                # å»æ±‰åŒ–æ¨¡å¼ç‰¹æ®Šå¤„ç†
                if is_dehash_mode:
                    if not filter_instance.image_filter.hash_file:
                        logger.error("[#sys_log]âŒ å»æ±‰åŒ–æ¨¡å¼éœ€è¦å“ˆå¸Œæ–‡ä»¶")
                        return False, "å»æ±‰åŒ–æ¨¡å¼éœ€è¦å“ˆå¸Œæ–‡ä»¶"
                    logger.info("[#sys_log]âœ… ä½¿ç”¨å»æ±‰åŒ–æ¨¡å¼å¤„ç†")
                
                # å¤„ç†å‹ç¼©åŒ…
                return filter_instance.process_archive(
                    path,
                    extract_mode=ExtractMode.RANGE,
                    extract_params=extract_params,
                    is_dehash_mode=is_dehash_mode
                )
            else:
                logger.warning(f"[#file_ops]è·³è¿‡éZIPæ–‡ä»¶: {path}")
                return False, "éZIPæ–‡ä»¶"
            
        except FileNotFoundError as e:
            logger.error(f"[#file_ops]è·¯å¾„ä¸å­˜åœ¨: {path}")
            raise
        except PermissionError as e:
            logger.error(f"[#file_ops]è·¯å¾„è®¿é—®æƒé™é”™è¯¯: {path}")
            raise
        except Exception as e:
            logger.error(f"[#file_ops]å¤„ç†è¿‡ç¨‹å‡ºé”™: {path}: {str(e)}")
            raise
            
    def process_directory(self, directory: str, filter_instance: RecruitCoverFilter, is_dehash_mode: bool = False, extract_params: dict = None):
        """å¤„ç†ç›®å½•æˆ–æ–‡ä»¶
        
        Args:
            directory: ç›®å½•æˆ–æ–‡ä»¶è·¯å¾„
            filter_instance: è¿‡æ»¤å™¨å®ä¾‹
            is_dehash_mode: æ˜¯å¦ä¸ºå»æ±‰åŒ–æ¨¡å¼
            extract_params: è§£å‹å‚æ•°
        """
        try:
            return self._process_single_archive((directory, filter_instance, extract_params, is_dehash_mode))
        except Exception as e:
            logger.error(f"[#sys_log]å¤„ç†å¤±è´¥ {directory}: {e}")
            return False, "å¤„ç†å¤±è´¥"

def setup_cli_parser():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨"""
    parser = argparse.ArgumentParser(description='æ‹›å‹Ÿå°é¢å›¾ç‰‡è¿‡æ»¤å·¥å…·')
    parser.add_argument('--hash-file', '-hf', type=str,
                      help='å“ˆå¸Œæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€é…ç½®ï¼‰')
    parser.add_argument('--hamming-threshold', '-ht', type=int, default=16,
                      help='æ±‰æ˜è·ç¦»é˜ˆå€¼ (é»˜è®¤: 16)')
    parser.add_argument('--clipboard', '-c', action='store_true',
                      help='ä»å‰ªè´´æ¿è¯»å–è·¯å¾„')
    parser.add_argument('--watermark-keywords', '-wk', nargs='*',
                      help='æ°´å°å…³é”®è¯åˆ—è¡¨ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤åˆ—è¡¨')
    parser.add_argument('--duplicate-filter-mode', '-dfm', type=str,
                      choices=['quality', 'watermark', 'hash'],
                      default='watermark',
                      help='é‡å¤è¿‡æ»¤æ¨¡å¼ (hash=å»æ±‰åŒ–æ¨¡å¼, watermark=å»æ°´å°æ¨¡å¼, quality=è´¨é‡æ¨¡å¼)')
    parser.add_argument('--extract-mode', '-em', type=str, 
                      choices=[ExtractMode.ALL, ExtractMode.RANGE],
                      default=ExtractMode.ALL, help='è§£å‹æ¨¡å¼ (é»˜è®¤: all)')
    parser.add_argument('--extract-range', '-er', type=str,
                      help='è§£å‹èŒƒå›´ (ç”¨äº range æ¨¡å¼ï¼Œæ ¼å¼: start:end)')
    parser.add_argument('--front-n', '-fn', type=int, default=3,
                      help='å¤„ç†å‰Nå¼ å›¾ç‰‡ (é»˜è®¤: 3)')
    parser.add_argument('--back-n', '-bn', type=int, default=5,
                      help='å¤„ç†åNå¼ å›¾ç‰‡ (é»˜è®¤: 5)')
    parser.add_argument('--workers', '-w', type=int, default=16,
                      help='æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°')
    parser.add_argument('path', nargs='*', help='è¦å¤„ç†çš„æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    return parser

def run_application(args):
    """è¿è¡Œåº”ç”¨ç¨‹åº"""
    try:
        # æ ¹æ®è¿‡æ»¤æ¨¡å¼åˆ¤æ–­æ˜¯å¦ä¸ºå»æ±‰åŒ–æ¨¡å¼
        is_dehash_mode = args.duplicate_filter_mode == 'hash'
        
        # æ·»åŠ æ¨¡å¼åˆ¤æ–­çš„æ—¥å¿—
        logger.info(f"[#sys_log]è¿è¡Œæ¨¡å¼: {'å»æ±‰åŒ–æ¨¡å¼' if is_dehash_mode else 'å»æ°´å°æ¨¡å¼'}")
        logger.info(f"[#sys_log]è¿‡æ»¤æ¨¡å¼: {args.duplicate_filter_mode}")

        paths = InputHandler.get_input_paths(
            cli_paths=args.path,
            use_clipboard=args.clipboard,
        )
        
        if not paths:
            logger.error("[#sys_log]æœªæä¾›ä»»ä½•æœ‰æ•ˆè·¯å¾„")
            return False
            
        # ä¿®æ”¹è¿‡æ»¤å™¨åˆå§‹åŒ–é€»è¾‘
        filter_instance = RecruitCoverFilter(
            hash_file=args.hash_file,
            hamming_threshold=args.hamming_threshold,
            # å¦‚æœæ˜¯å»æ±‰åŒ–æ¨¡å¼ï¼Œåˆ™ä¸ä½¿ç”¨æ°´å°å…³é”®è¯
            watermark_keywords=None if is_dehash_mode else args.watermark_keywords,
            max_workers=args.workers
        )

        # å¦‚æœæ˜¯å»æ±‰åŒ–æ¨¡å¼ä¸”æ²¡æœ‰æŒ‡å®šå“ˆå¸Œæ–‡ä»¶ï¼Œè‡ªåŠ¨å‡†å¤‡å“ˆå¸Œæ–‡ä»¶
        if is_dehash_mode and not args.hash_file:
            recruit_folder = r"E:\1EHV\[01æ‚]\[zzzå»å›¾]"
            hash_file = filter_instance.prepare_hash_file(recruit_folder)
            if not hash_file:
                logger.error("[#sys_log]âŒ å»æ±‰åŒ–æ¨¡å¼éœ€è¦å“ˆå¸Œæ–‡ä»¶ï¼Œä½†å‡†å¤‡å¤±è´¥")
                return False

        # å‡†å¤‡è§£å‹å‚æ•°
        extract_params = {
            'front_n': args.front_n,
            'back_n': args.back_n
        }
        
        if args.extract_mode == ExtractMode.RANGE and args.extract_range:
            extract_params['range_str'] = args.extract_range
            
        # åˆ›å»ºåº”ç”¨ç¨‹åºå®ä¾‹
        app = Application(max_workers=args.workers)
        
        # è®°å½•å¤„ç†å‚æ•°
        logger.info(f"[#sys_log]å¤„ç†å‚æ•°: front_n={args.front_n}, back_n={args.back_n}, mode={args.extract_mode}")
        if args.extract_range:
            logger.info(f"[#sys_log]è§£å‹èŒƒå›´: {args.extract_range}")
        
        total_count = len(paths)
        success_count = 0
        error_count = 0
        error_details = []
        
        # æ˜¾ç¤ºåˆå§‹å…¨å±€è¿›åº¦
        logger.info(f"[@global_progress]æ€»ä»»åŠ¡è¿›åº¦ (0/{total_count}) 0%")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å‹ç¼©åŒ…
        with ThreadPoolExecutor(max_workers=args.workers) as executor:
            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            future_to_archive = {
                executor.submit(
                    app._process_single_archive, 
                    (archive, filter_instance, extract_params, is_dehash_mode)
                ): archive for archive in paths
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(future_to_archive):
                archive = future_to_archive[future]
                try:
                    # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ–‡ä»¶è¿›åº¦
                    logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)}")
                    logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 0%")
                    
                    success, error_msg = future.result()
                    if success:
                        success_count += 1
                        logger.info(f"[#file_ops]âœ… æˆåŠŸå¤„ç†: {os.path.basename(archive)}")
                        # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸º100%
                        logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)}")
                        logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 100%")
                    else:
                        error_count += 1
                        error_msg = f"å¤„ç†è¿”å›å¤±è´¥: {os.path.basename(archive)}, åŸå› : {error_msg}"
                        error_details.append(error_msg)
                        logger.warning(f"[#file_ops]âš ï¸ {error_msg}")
                        # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸ºå¤±è´¥
                        logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)} (å¤±è´¥)")
                except Exception as e:
                    error_count += 1
                    import traceback
                    error_trace = traceback.format_exc()
                    error_msg = f"å¤„ç†å‡ºé”™ {os.path.basename(archive)}: {str(e)}\n{error_trace}"
                    error_details.append(error_msg)
                    logger.error(f"[#file_ops]âŒ {error_msg}")
                    # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸ºé”™è¯¯
                    logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)} (é”™è¯¯)")
                
                # æ›´æ–°å…¨å±€è¿›åº¦
                completed = success_count + error_count
                progress = (completed / total_count) * 100
                logger.info(f"[@global_progress]æ€»ä»»åŠ¡è¿›åº¦ ({completed}/{total_count}) {progress:.1f}%")
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        logger.info(f"[#sys_log]å¤„ç†å®Œæˆ âœ…æˆåŠŸ: {success_count} âŒå¤±è´¥: {error_count} æ€»æ•°: {total_count}")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œè¾“å‡ºè¯¦ç»†ä¿¡æ¯
        if error_details:
            logger.info("[#sys_log]é”™è¯¯è¯¦æƒ…:")
            for i, error in enumerate(error_details, 1):
                logger.info(f"[#sys_log]{i}. {error}")
        
        return True
        
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"[#sys_log]ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}\n{error_trace}")
        return False

# å®šä¹‰é¢„è®¾é…ç½®

# ç›´æ¥ä½¿ç”¨textual_presetæ¨¡å—åˆ›å»ºTUIç•Œé¢
def run_tui():
    """è¿è¡ŒTUIç•Œé¢"""
    # åˆ›å»ºé¢„è®¾é…ç½®åˆ—è¡¨
    preset_configs = {
        "å»æ°´å°æ¨¡å¼": {
            "description": "æ£€æµ‹å¹¶åˆ é™¤å¸¦æ°´å°çš„å›¾ç‰‡",
            "checkbox_options": ["clipboard"],
            "input_values": {
                "hamming_threshold": "16",
                "front_n": "3",
                "back_n": "0",
                "duplicate_filter_mode": "watermark"
            }
        },
        "å»æ±‰åŒ–æ¨¡å¼": {
            "description": "å¤„ç†å‰åNå¼ å›¾ç‰‡å¹¶ä½¿ç”¨å“ˆå¸Œå»é‡",
            "checkbox_options": ["clipboard"],
            "input_values": {
                "hamming_threshold": "16",
                "front_n": "3",
                "back_n": "5",
                "duplicate_filter_mode": "hash"
            }
        }
    }
    # åˆ›å»ºTUIåº”ç”¨
    parser = setup_cli_parser()
    app = create_config_app(
        program=__file__,
        parser=parser,
        title="æ‹›å‹Ÿå°é¢å›¾ç‰‡è¿‡æ»¤å·¥å…·",
        preset_configs=preset_configs,
        # on_run=run_with_args
    )
    
    # è¿è¡ŒTUIåº”ç”¨
    app.run()
    return True

def run_with_args(params):
    """ç»Ÿä¸€å¤„ç†å‚æ•°å‡½æ•° 
    
    Args:
        params: åŒ…å«å‚æ•°çš„å­—å…¸ï¼Œæ ¼å¼ä¸º {
            'options': {'--clipboard': True, ...}, 
            'inputs': {'--hamming-threshold': '16', ...}
        }
        
    Returns:
        bool: æ‰§è¡Œæ˜¯å¦æˆåŠŸ
    """
    try:
        # æ„å»ºå‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨
        cli_args = []
        
        # æ·»åŠ é€‰é¡¹å‚æ•°
        for opt, enabled in params.get('options', {}).items():
            if enabled:
                cli_args.append(opt)
                
        # æ·»åŠ è¾“å…¥å‚æ•°
        for arg_name, arg_value in params.get('inputs', {}).items():
            if arg_value:  # æ’é™¤ç©ºå€¼
                cli_args.append(arg_name)
                cli_args.append(arg_value)
        
        # æ·»åŠ pathå‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'path' in params:
            cli_args.extend(params['path'])
        
        # åˆ›å»ºå‘½ä»¤è¡Œè§£æå™¨å¹¶è§£æå‚æ•°
        parser = setup_cli_parser()
        args = parser.parse_args(cli_args)
        
        # æ ¹æ®è¿‡æ»¤æ¨¡å¼åˆ¤æ–­æ˜¯å¦ä¸ºå»æ±‰åŒ–æ¨¡å¼
        is_dehash_mode = args.duplicate_filter_mode == 'hash'
        
        # æ·»åŠ æ¨¡å¼åˆ¤æ–­çš„æ—¥å¿—
        logger.info(f"[#sys_log]è¿è¡Œæ¨¡å¼: {'å»æ±‰åŒ–æ¨¡å¼' if is_dehash_mode else 'å»æ°´å°æ¨¡å¼'}")
        logger.info(f"[#sys_log]è¿‡æ»¤æ¨¡å¼: {args.duplicate_filter_mode}")

        paths = InputHandler.get_input_paths(
            cli_paths=args.path if hasattr(args, 'path') else [],
            use_clipboard=args.clipboard,
        )
        
        if not paths:
            logger.error("[#sys_log]æœªæä¾›ä»»ä½•æœ‰æ•ˆè·¯å¾„")
            return False
            
        # åˆ›å»ºè¿‡æ»¤å™¨å®ä¾‹
        filter_instance = RecruitCoverFilter(
            hash_file=args.hash_file,
            hamming_threshold=args.hamming_threshold,
            # å¦‚æœæ˜¯å»æ±‰åŒ–æ¨¡å¼ï¼Œåˆ™ä¸ä½¿ç”¨æ°´å°å…³é”®è¯
            watermark_keywords=None if is_dehash_mode else args.watermark_keywords,
            max_workers=args.workers
        )

        # å¦‚æœæ˜¯å»æ±‰åŒ–æ¨¡å¼ä¸”æ²¡æœ‰æŒ‡å®šå“ˆå¸Œæ–‡ä»¶ï¼Œè‡ªåŠ¨å‡†å¤‡å“ˆå¸Œæ–‡ä»¶
        if is_dehash_mode and not args.hash_file:
            recruit_folder = r"E:\1EHV\[01æ‚]\[zzzå»å›¾]"
            hash_file = filter_instance.prepare_hash_file(recruit_folder)
            if not hash_file:
                logger.error("[#sys_log]âŒ å»æ±‰åŒ–æ¨¡å¼éœ€è¦å“ˆå¸Œæ–‡ä»¶ï¼Œä½†å‡†å¤‡å¤±è´¥")
                return False

        # å‡†å¤‡è§£å‹å‚æ•°
        extract_params = {
            'front_n': args.front_n,
            'back_n': args.back_n
        }
        
        if args.extract_mode == ExtractMode.RANGE and args.extract_range:
            extract_params['range_str'] = args.extract_range
            
        # åˆ›å»ºåº”ç”¨ç¨‹åºå®ä¾‹
        app = Application(max_workers=args.workers)
        
        # è®°å½•å¤„ç†å‚æ•°
        logger.info(f"[#sys_log]å¤„ç†å‚æ•°: front_n={args.front_n}, back_n={args.back_n}, mode={args.extract_mode}")
        if args.extract_range:
            logger.info(f"[#sys_log]è§£å‹èŒƒå›´: {args.extract_range}")
        
        total_count = len(paths)
        success_count = 0
        error_count = 0
        error_details = []
        
        # æ˜¾ç¤ºåˆå§‹å…¨å±€è¿›åº¦
        logger.info(f"[@global_progress]æ€»ä»»åŠ¡è¿›åº¦ (0/{total_count}) 0%")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å‹ç¼©åŒ…
        with ThreadPoolExecutor(max_workers=args.workers) as executor:
            # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
            future_to_archive = {
                executor.submit(
                    app._process_single_archive, 
                    (archive, filter_instance, extract_params, is_dehash_mode)
                ): archive for archive in paths
            }
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(future_to_archive):
                archive = future_to_archive[future]
                try:
                    # æ˜¾ç¤ºå½“å‰å¤„ç†çš„æ–‡ä»¶è¿›åº¦
                    logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)}")
                    logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 0%")
                    
                    success, error_msg = future.result()
                    if success:
                        success_count += 1
                        logger.info(f"[#file_ops]âœ… æˆåŠŸå¤„ç†: {os.path.basename(archive)}")
                        # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸º100%
                        logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)}")
                        logger.info(f"[@path_progress]å½“å‰è¿›åº¦: 100%")
                    else:
                        error_count += 1
                        error_msg = f"å¤„ç†è¿”å›å¤±è´¥: {os.path.basename(archive)}, åŸå› : {error_msg}"
                        error_details.append(error_msg)
                        logger.warning(f"[#file_ops]âš ï¸ {error_msg}")
                        # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸ºå¤±è´¥
                        logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)} (å¤±è´¥)")
                except Exception as e:
                    error_count += 1
                    import traceback
                    error_trace = traceback.format_exc()
                    error_msg = f"å¤„ç†å‡ºé”™ {os.path.basename(archive)}: {str(e)}\n{error_trace}"
                    error_details.append(error_msg)
                    logger.error(f"[#file_ops]âŒ {error_msg}")
                    # æ›´æ–°å½“å‰æ–‡ä»¶è¿›åº¦ä¸ºé”™è¯¯
                    logger.info(f"[#path_progress]å¤„ç†æ–‡ä»¶: {os.path.basename(archive)} (é”™è¯¯)")
                
                # æ›´æ–°å…¨å±€è¿›åº¦
                completed = success_count + error_count
                progress = (completed / total_count) * 100
                logger.info(f"[@global_progress]æ€»ä»»åŠ¡è¿›åº¦ ({completed}/{total_count}) {progress:.1f}%")
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        logger.info(f"[#sys_log]å¤„ç†å®Œæˆ âœ…æˆåŠŸ: {success_count} âŒå¤±è´¥: {error_count} æ€»æ•°: {total_count}")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œè¾“å‡ºè¯¦ç»†ä¿¡æ¯
        if error_details:
            logger.info("[#sys_log]é”™è¯¯è¯¦æƒ…:")
            for i, error in enumerate(error_details, 1):
                logger.info(f"[#sys_log]{i}. {error}")
        
        return success_count > 0
        
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"[#sys_log]ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}\n{error_trace}")
        return False

# å…¥å£å‡½æ•°
if __name__ == '__main__':
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        parser = setup_cli_parser()
        args = parser.parse_args()
        
        # æ„å»ºå‚æ•°å­—å…¸
        params = {
            'options': {},
            'inputs': {},
            'path': args.path
        }
        
        # å°†argsè½¬æ¢ä¸ºparamsæ ¼å¼
        args_dict = vars(args)
        for arg_name, value in args_dict.items():
            if isinstance(value, bool) and value:
                # å¸ƒå°”å‚æ•°
                params['options'][f'--{arg_name.replace("_", "-")}'] = value
            elif value is not None and arg_name != 'path':
                # å…¶ä»–éNoneå‚æ•°
                params['inputs'][f'--{arg_name.replace("_", "-")}'] = str(value)
            
        # è¿è¡Œç¨‹åº
        success = run_with_args(params)
        sys.exit(0 if success else 1)
    else:
        # TUIæ¨¡å¼
        success = run_tui()
        sys.exit(0 if success else 1)